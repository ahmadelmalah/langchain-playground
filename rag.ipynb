{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f40cb3d7-72c7-4f3b-8be1-4fa6f16acf9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "if not os.environ.get(\"OPENAI_API_KEY\"):\n",
    "    os.environ[\"OPENAI_API_KEY\"] = \"OPENAI_API_KEY\"\n",
    "    os.environ[\"LANGCHAIN_TRACING_V2\"] = \"true\"\n",
    "    os.environ[\"LANGCHAIN_ENDPOINT\"] = \"https://api.smith.langchain.com\"\n",
    "    os.environ[\"LANGCHAIN_API_KEY\"] = \"LANGCHAIN_API_KEY\"\n",
    "    os.environ[\"LANGCHAIN_PROJECT\"] = \"rag_tutorial_1\"\n",
    "    os.environ[\"USER_AGENT\"] = \"Mozilla/5.0 (compatible; MyBot/1.0)\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cd6ca4fe-8cd2-4157-8267-409b34fce2e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "llm = ChatOpenAI(model=\"gpt-4o-mini\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9fd679dc-95f2-4b1e-94f4-e27de46780bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import OpenAIEmbeddings\n",
    "\n",
    "embeddings = OpenAIEmbeddings(model=\"text-embedding-3-large\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b82473d7-e85d-4c38-a681-7fc1bc384464",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.vectorstores import InMemoryVectorStore\n",
    "\n",
    "vector_store = InMemoryVectorStore(embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a45cb1bc-31db-466f-a4fd-e7f0d9227d36",
   "metadata": {},
   "outputs": [],
   "source": [
    "import bs4\n",
    "from langchain import hub\n",
    "from langchain_community.document_loaders import WebBaseLoader\n",
    "from langchain_core.documents import Document\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "from langgraph.graph import START, StateGraph\n",
    "from typing_extensions import List, TypedDict\n",
    "\n",
    "# Load and chunk contents of the blog\n",
    "loader = WebBaseLoader(\n",
    "    web_paths=(\"https://lilianweng.github.io/posts/2023-06-23-agent/\",),\n",
    "    bs_kwargs=dict(\n",
    "        parse_only=bs4.SoupStrainer(\n",
    "            class_=(\"post-content\", \"post-title\", \"post-header\")\n",
    "        )\n",
    "    ),\n",
    ")\n",
    "docs = loader.load()\n",
    "\n",
    "text_splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=200)\n",
    "all_splits = text_splitter.split_documents(docs)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a6336f98-928c-4da6-b292-43f7607e17b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Index chunks\n",
    "_ = vector_store.add_documents(documents=all_splits)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9e2a77e8-d361-4df4-b18b-0a50132fdaab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define prompt for question-answering\n",
    "prompt = hub.pull(\"rlm/rag-prompt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "bf49bc10-3951-425d-a60f-a39aaa41f84d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define state for application\n",
    "class State(TypedDict):\n",
    "    question: str\n",
    "    context: List[Document]\n",
    "    answer: str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c165b2c2-40cc-4d33-a610-d5e04ec403e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Define application steps\n",
    "def retrieve(state: State):\n",
    "    retrieved_docs = vector_store.similarity_search(state[\"question\"])\n",
    "    return {\"context\": retrieved_docs}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "bbfde0b1-7b3d-4deb-990b-dac5dd4acf8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate(state: State):\n",
    "    docs_content = \"\\n\\n\".join(doc.page_content for doc in state[\"context\"])\n",
    "    messages = prompt.invoke({\"question\": state[\"question\"], \"context\": docs_content})\n",
    "    response = llm.invoke(messages)\n",
    "    return {\"answer\": response.content}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "61fece7f-c66b-4eb4-8e9f-9bc6ca0e686d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile application and test\n",
    "graph_builder = StateGraph(State).add_sequence([retrieve, generate])\n",
    "graph_builder.add_edge(START, \"retrieve\")\n",
    "graph = graph_builder.compile()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6f482736-017a-4e80-89cc-51160c9ca2e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Task Decomposition is the process of breaking down a complex task into smaller, manageable steps to facilitate problem-solving. Techniques like Chain of Thought (CoT) allow models to think step by step, while methods like Tree of Thoughts explore multiple reasoning possibilities at each step. This approach can be executed through simple prompting, task-specific instructions, or human inputs.\n"
     ]
    }
   ],
   "source": [
    "response = graph.invoke({\"question\": \"What is Task Decomposition?\"})\n",
    "print(response[\"answer\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a076bda-fe2a-414c-8806-d22e701a4ca1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
